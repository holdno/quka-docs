---
title: 入门
---

# 欢迎使用 {process.env.siteName}

快速构建个人第二“大脑”

{process.env.siteName} 是一个基于 LLM(大语言模型) 实现的赛博记忆应用，希望能够借此扩容 个人“记忆”。  
提供的功能包括 记忆碎片的录入、基于 LLM 的记忆问答、日记(工作日志)、生活管家 等功能。

## 设计理念

将 {process.env.siteName} 想象成一个无尽的黑洞，将有用的记忆点、知识碎片随便往里丢，不用操心记忆被如何存放在哪里，在需要使用时一问便知。

- UI 符合 C 端用户交互逻辑，做到开箱即用
- API 可以满足企业用户构建知识库问答体系

## 为什么使用{process.env.siteName}?

生活中，无论线上还是线下，经常会遇到一些琐碎的“记忆”

- 在小红书中收藏了一个周末可以去的宝藏打卡地
- 在抖音里又收藏了一个宝藏咖啡店

但真的到了周末以后，我们想要去宝藏打卡地，但忘记是在哪个平台收藏的了，微博？不是... 抖音？也不是... 奇了怪了，我明明记得我收藏了！哦~是在小红书...  
类似的场景在我们生活中随处可见，在“记忆”的当时，我们记得很清楚，但经过几日生活的旅程后，可能新的惊喜已经默默的在大脑深处取代了曾经的美好。

比如作者在编写该文档前，调研了好几个开源文档建设工具，并为每个文档工具记录了一份“记忆”
![文档建设工具记忆截图](/文档建设工具记忆截图.png)

在回顾时只需要向{process.env.siteName}提问 “我都记录了哪些文档建设工具？”，便可以得到简单的总结：  
![回忆文档建设工具Demo.png](/回忆文档建设工具Demo.png)

## 与笔记软件有什么不同？

传统的笔记软件，想要做到快速找到记录的内容往往需要我们精心管理每篇笔记的分类，记住笔记的标题与关键字。

一篇记录了“XX 城市家具博览会”的内容，在搜索时我们往往会把它记成展览或会展，但无论我们搜索“展览”还是“会展”它都不会出现，除非你想到它是“博览会”，这就是传统笔记软件的硬伤，当我们记忆的内容越来越多，通过关键字匹配越来越难满足我们快速搜索的需求。

而{process.env.siteName}借助 LLM 技术，让大语言模型理解你的需求，通过复杂的 LLM 工作流即可实现“同义”内容的搜索，再结合大语言模型的推理能力，使它可以像真实的人工助理一样来回答你的问题。

![](/公园场景Demo.png)
